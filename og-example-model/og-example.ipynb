{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenGradient Modelthon Workflow Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will provide an example workflow of how modelthon participants can train their model, convert it to ONNX format, upload it to the OpenGradient model hub, and execute an inference on the OpenGradient network.\n",
    "\n",
    "Here, we will demonstrate the following pipeline:\n",
    "1. Load data using utils functions into your model\n",
    "2. Train the model using the included training utilities\n",
    "3. Convert the model to ONNX\n",
    "4. Verify predictions are the same pre and post ONNX conversion\n",
    "5. Utilize the `OG-SDK` to upload the model to the OpenGradient network & run a test inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Example Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import os\n",
    "\n",
    "from utils.training import train_linear_model\n",
    "\n",
    "DATA_PATH = \"../data/ETHUSDT_1h_spot_forecast_training.csv\"\n",
    "ONNX_PATH = \"eth_ridge_regression.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Feature Preparation\n",
    "This cell loads the training data and prepares features using the LinearTimeSeriesPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Data ===\n",
      "\n",
      "Dataset Summary:\n",
      "Total samples: 14,630\n",
      "Number of features: 81\n",
      "Feature shape: (14630, 81)\n",
      "Target shape: (14630,)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Loading Data ===\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "feature_cols = []\n",
    "for col_type in ['open', 'high', 'low', 'close']:\n",
    "    feature_cols.extend([f'{col_type}_ETHUSDT_lag{i}' for i in range(1, 11)])\n",
    "for col_type in ['open', 'high', 'low', 'close']:\n",
    "    feature_cols.extend([f'{col_type}_BTCUSDT_lag{i}' for i in range(1, 11)])\n",
    "feature_cols.append('hour_of_day')\n",
    "\n",
    "features = df[feature_cols].values\n",
    "target = df['target_ETHUSDT'].values\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"Total samples: {len(features):,}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Feature shape: {features.shape}\")\n",
    "print(f\"Target shape: {target.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Training\n",
    "Trains the model using time series cross-validation and displays performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Model ===\n",
      "\n",
      "Top 10 most important features:\n",
      "                    importance\n",
      "feature                       \n",
      "close_ETHUSDT_lag6    0.000452\n",
      "open_ETHUSDT_lag5     0.000450\n",
      "open_ETHUSDT_lag3     0.000390\n",
      "close_ETHUSDT_lag4    0.000385\n",
      "open_BTCUSDT_lag1     0.000318\n",
      "close_BTCUSDT_lag2    0.000315\n",
      "open_BTCUSDT_lag8     0.000298\n",
      "close_BTCUSDT_lag9    0.000297\n",
      "close_ETHUSDT_lag8    0.000295\n",
      "open_ETHUSDT_lag7     0.000286\n",
      "\n",
      "Model Performance Metrics:\n",
      "- MSE: 0.00003855 (±0.00001430)\n",
      "- RMSE: 0.0061 (±0.0013)\n",
      "- MAE: 0.0039 (±0.0009)\n",
      "- R²: -0.0521 (±0.0234)\n",
      "- DirectionalAcc: 0.5434 (±0.0186)\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"\\n=== Training Model ===\")\n",
    "model, metrics, model_info = train_linear_model(features, target, feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ONNX Conversion\n",
    "Converts the trained model to ONNX format for deployment\n",
    "\n",
    "**Make sure the name of your ONNX model input is `candles`. This is crucial for the evaluation phase!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxmltools\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "def convert_to_onnx(model, input_dim, output_path=\"eth_ridge_regression.onnx\"):\n",
    "    \"\"\"Convert trained Ridge Regression model to ONNX format\"\"\"\n",
    "    print(f\"\\nConverting model to ONNX format: {output_path}\")\n",
    "    \n",
    "    # Define input type - our features are float32\n",
    "    initial_type = [('candles', FloatTensorType([None, input_dim]))]\n",
    "    \n",
    "    # Convert to ONNX using onnxmltools with skl2onnx backend\n",
    "    onnx_model = onnxmltools.convert_sklearn(\n",
    "        model.model,  \n",
    "        name='RidgePredictor',\n",
    "        initial_types=initial_type,  \n",
    "        target_opset=15\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    onnxmltools.utils.save_model(onnx_model, output_path)\n",
    "    print(\"Conversion complete\")\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Converting to ONNX ===\n",
      "\n",
      "Converting model to ONNX format: eth_ridge_regression.onnx\n",
      "Conversion complete\n"
     ]
    }
   ],
   "source": [
    "# Convert to ONNX\n",
    "print(\"\\n=== Converting to ONNX ===\")\n",
    "onnx_path = convert_to_onnx(model, len(feature_cols), ONNX_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Verification\n",
    "Verifies that the ONNX model produces the same predictions as the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Verifying ONNX Model ===\n",
      "\n",
      "Prediction Comparison:\n",
      "Original model: [ 0.00025253  0.00025462  0.0000617  -0.00022836  0.00005977]\n",
      "ONNX model:     [ 0.00025253  0.00025462  0.0000617  -0.00022836  0.00005977]\n",
      "\n",
      "Max difference: 0.00000000\n",
      "\n",
      "✅ ONNX model predictions match original model within tolerance\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Verifying ONNX Model ===\")\n",
    "try:\n",
    "    if not os.path.exists(ONNX_PATH):\n",
    "        raise FileNotFoundError(f\"ONNX model not found at {ONNX_PATH}\")\n",
    "        \n",
    "    session = ort.InferenceSession(ONNX_PATH)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    sample_features = features[:5].astype(np.float32)\n",
    "    \n",
    "    # Compare predictions with consistent formatting\n",
    "    original_pred = model.predict(sample_features)\n",
    "    onnx_pred = session.run(None, {input_name: sample_features})[0].flatten()\n",
    "    \n",
    "    print(\"\\nPrediction Comparison:\")\n",
    "    np.set_printoptions(precision=8, suppress=True)\n",
    "    print(f\"Original model: {original_pred}\")\n",
    "    print(f\"ONNX model:     {onnx_pred}\")\n",
    "    \n",
    "    max_diff = np.max(np.abs(original_pred - onnx_pred))\n",
    "    print(f\"\\nMax difference: {max_diff:.8f}\")\n",
    "    \n",
    "    is_close = np.allclose(original_pred, onnx_pred, rtol=1e-3, atol=1e-4)\n",
    "    \n",
    "    if is_close:\n",
    "        print(\"\\n✅ ONNX model predictions match original model within tolerance\")\n",
    "    else:\n",
    "        print(\"\\n❌ Warning: ONNX model predictions exceed tolerance threshold!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error during verification: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading to the OpenGradient Model Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After converting your model to ONNX format, you can upload it to the OpenGradient Model Hub using the OpenGradient SDK.  \n",
    "For detailed documentation, see the [Model Management Guide](https://docs.opengradient.ai/developers/python_sdk/model_management.html).\n",
    "\n",
    "Basic workflow:\n",
    "1. Install the SDK: `pip install opengradient`\n",
    "2. Initialize the client with your credentials\n",
    "3. Create a model repository\n",
    "4. Create a version\n",
    "5. Upload your ONNX file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opengradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opengradient as og\n",
    "\n",
    "og.init(private_key=\"<private_key>\", email=\"<email>\", password=\"<password>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating & Uploading Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'og-modelthon-eth-ridge-regression', 'versionString': '0.01'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og.create_model(model_name=\"og-modelthon-eth-ridge-regression\", model_desc=\"example ridge regression model for modelthon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_cid': 'QmTqHvTPUDogFHDB1fYLwSFxVX5zFurbnxLkB436n96Qod', 'size': 640}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og.upload(model_path=\"./eth_ridge_regression.onnx\", model_name=\"og-modelthon-eth-ridge-regression\", version='0.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to create a new version of your model, invoke the `create_version` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versionString = og.create_version(model_name=\"<model_name>\", notes=\"<notes>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running an Inference on the OpenGradient Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For more detailed documentation on running inferences, see the [Verifiable Inference documentation](https://docs.opengradient.ai/developers/python_sdk/inference.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical Precision:**\n",
    "- Maximum precision: 19 decimal places\n",
    "- Input values exceeding this precision will cause contract execution to fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1, 81)\n",
      "\n",
      "Local Model Prediction: [0.00025005]\n",
      "\n",
      "Prediction from OpenGradient: {'variable': array([[0.00025259]], dtype=float32)}\n",
      "\n",
      "Transaction Hash: 17d7b33d387a9c2eaa6e0988741219e2bf0636c929c9338913fbafd45fa86736\n"
     ]
    }
   ],
   "source": [
    "sample_features = features[0:1].astype(np.float32)  # Take first sample, keeping 2D shape\n",
    "print(f\"Input shape: {sample_features.shape}\")\n",
    "\n",
    "# Run inference using the uploaded model\n",
    "tx_hash, prediction = og.infer(\n",
    "    model_cid=\"QmTqHvTPUDogFHDB1fYLwSFxVX5zFurbnxLkB436n96Qod\",\n",
    "    model_input={\n",
    "        \"candles\": sample_features.tolist()\n",
    "    },\n",
    "    inference_mode=og.InferenceMode.VANILLA\n",
    ")\n",
    "\n",
    "print(f\"\\nLocal Model Prediction: {model.predict(sample_features)}\")\n",
    "print(f\"\\nPrediction from OpenGradient: {prediction}\")\n",
    "print(f\"\\nTransaction Hash: {tx_hash}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check out the transaction on the block explorer:\n",
    "http://3.145.62.2/tx/0x5972c48b1a5f1320f964d181ba49645fba4fe571e98b05ef62fc2fea617edd3f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
